# Large-Scale Coordination Configuration
# For 8+ agent coordination on complex problems

runner: "episode_runner"
mac: "basic_mac"
learner: "q_learner"
t_max: 3000000  # Extended training for complex coordination
test_interval: 75000
test_nepisode: 32
text_embed_dim: 2048  # Larger embedding dimension
n_agents: 8  # More agents for complex coordination
belief_dim: 256  # Larger belief state
batch_size_run: 1
state_shape: 2048

# MAC Configuration
agent_output_type: "q_values"
action_selector: "multinomial"
obs_last_action: false
obs_agent_id: true
use_causal_mask: false
max_seq_length: 2048
n_actions: 2

# LLM Configuration - Use powerful models for coordination
llm_model_name: "gpt2"
together_api_key: "${TOGETHER_API_KEY}"
coordinator_model: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
executor_model: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
commitment_embedding_model_name: "BAAI/bge-large-en-v1.5"

# Environment Settings
env: "huggingface_dataset_env"
env_args:
  hf_dataset_path: "gsm8k"
  hf_dataset_config_name: "main"
  dataset_split: "train"
  question_field_name: "question"
  answer_field_name: "answer"
  max_question_length: 2048  # Handle longer problems
  max_answer_length: 512
  dataset_streaming: false

# Training Configuration for Large Scale
train:
  episodes_per_task: 150  # More episodes for complex coordination
  buffer_size: 64  # Larger buffer for better learning
  batch_size: 32  # Larger batch size
  update_interval: 16
  optimizer: "adam"
  learning_rate: 0.0005  # Lower learning rate for stability
  coordinator_learning_rate: 0.0003
  gamma: 0.99

# Learning rates
lr: 0.0005
belief_net_lr: 0.0005
encoder_lr: 0.0005
mixer_lr: 0.0005
weight_decay: 0.0001  # Add some regularization

# Network Architecture for Large Scale
arch:
  entity_dim: 512  # Larger entity dimension
  attention_heads: 8  # More attention heads
  transformer_blocks: 4  # More layers
  key_dim: 64
  mlp_hidden_size: 512
  feedforward_size: 2048
  dropout_rate: 0.15  # Slightly higher dropout
  layer_norm_epsilon: 0.00001

# Mixer Configuration
prompt_attention_heads: 4
commitment_embedding_dim: 1024

# Temperature and Sampling
sampling:
  temperature_min: 0.05
  temperature_max: 1.5
  p_min: 0.05
  p_max: 0.95

# Reward Configuration
reward:
  max_value: 1.0
  initial_weights: [0.3, 0.5, 0.2]  # Adjusted for coordination
  eta_alpha: 0.0005
  dynamic_alpha_update: true
  r_expected_source: "q_value"
  al_weight: 0.25
  ts_weight: 0.55
  cc_weight: 0.2  # Higher coordination weight
  cc_reward_placeholder_value: 0.15

# Loss Weights
loss:
  belief_weight: 0.15
  encoder_weight: 0.15
  mixing_weight: 0.15

# Early Stopping
early_stopping:
  commitment_threshold: 0.005  # Tighter convergence
  loss_threshold: 0.00005
  reward_threshold: 0.75
  patience: 8  # More patience for complex coordination

# System Settings
system:
  use_cuda: true
  device_num: 0
  seed: 42
  debug: false

# Logging Settings
logging:
  use_tensorboard: true
  log_interval: 5000  # Less frequent logging
  save_model: true
  save_model_interval: 25000
  checkpoint_path: "./models/large_scale"
  log_path: "./logs/large_scale"
  experiment_name: "large_scale_8_agents"

# LLM Configuration Block
llm:
  together_api_key: "${TOGETHER_API_KEY}"
  coordinator_model: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
  executor_model: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
  max_tokens: 3072  # Longer responses for complex problems 